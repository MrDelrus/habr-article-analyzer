{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbec9235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score\n",
    "\n",
    "from habr_article_analyzer.data import load_dataset_from_zst\n",
    "from habr_article_analyzer.data_loader import HabrDataset\n",
    "from habr_article_analyzer.models.baseline.baseline import BaselineWord2VecKNN\n",
    "from habr_article_analyzer.models.encoders.word2vec_encoder import (\n",
    "    BilingualWord2VecEncoder,\n",
    ")\n",
    "from habr_article_analyzer.settings import data_settings, settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4200d273",
   "metadata": {},
   "source": [
    "# Baseline\n",
    "\n",
    "*Author: Nikita Zolin*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8c262e",
   "metadata": {},
   "source": [
    "The goal of this notebook is to prepare the baseline. Our task: predict the probability of each hub for the given text. Let's explain how the model will work:\n",
    "\n",
    "1. We take two inputs: text and hub, which we need to map to some vectors. Model `A` will map text to some vector in $R^n$, model `B` will map hub to some vector in $R^m$.\n",
    "2. We concatenate these vectors to get one vector in $R^{n+m}$.\n",
    "3. Model `C` estimates the probability based on this vector.\n",
    "\n",
    "In this notebook we will use word2vec for models `A` and `B` and we will adjust KNN for model `C`.\n",
    "\n",
    "However, before fitting the model we need to gather the dataset. Here, as it's just a baseline, we will simply take one positive and three random negative hubs for each text. This logic is implemented in [data_utils](../../src/habr_article_analyzer/data_utils/) and was run as a module before the code below.\n",
    "\n",
    "Then, we need to install some pretrained word2vec. Let's download them: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118f221d-1d93-4435-830d-586565043915",
   "metadata": {},
   "source": [
    "## Encoders\n",
    "\n",
    "We will take the small ones to run it locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44f8e4ee-3025-4c4a-a414-90ee6dd62c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kv_en = api.load(\"glove-wiki-gigaword-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "137c49d2-2450-40f8-b3f3-96c8bbe0a851",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kv_ru = api.load(\"word2vec-ruscorpora-300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0682fa59-da66-45a9-9a5c-10d384518b1c",
   "metadata": {},
   "source": [
    "## Model run\n",
    "\n",
    "Now we can safely run the model and check the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66b78d05-367b-475b-bdf9-1cd06e0243a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading dataset: 1751498it [01:26, 20150.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# Prepare mini-dataset for local run\n",
    "np.random.seed(data_settings.random_seed)\n",
    "\n",
    "dataset = HabrDataset(\n",
    "    path=settings.raw_data_dir / \"train_with_negatives.jsonl.zst\",\n",
    "    columns=[\"text\", \"hub\", \"label\"],\n",
    "    batch_size=data_settings.batch_size,\n",
    ")\n",
    "\n",
    "selected_rows = []\n",
    "for batch_df in dataset:\n",
    "    if np.random.rand() < 0.1:  # Select 10% of random rows\n",
    "        selected_rows.append(batch_df)\n",
    "\n",
    "train_df_sample = pd.concat(selected_rows, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d76f6ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = BilingualWord2VecEncoder(kv_ru=kv_ru, kv_en=kv_en)\n",
    "\n",
    "model = BaselineWord2VecKNN(text_encoder=encoder, hub_encoder=encoder)\n",
    "\n",
    "model.fit(\n",
    "    train_df_sample[\"text\"].tolist(),\n",
    "    train_df_sample[\"hub\"].tolist(),\n",
    "    train_df_sample[\"label\"].tolist(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd6e8e1",
   "metadata": {},
   "source": [
    "And let's check the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7574b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading records: 437367it [00:31, 13881.88it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 0.7991020106606943),\n",
       " (1, 1.0),\n",
       " (1, 0.7991020106606943),\n",
       " (1, 0.7991020106606943),\n",
       " (0, 0.7991020106606943),\n",
       " (0, 0.7991020106606943),\n",
       " (0, 0.7991020106606943),\n",
       " (0, 0.20176122508297176),\n",
       " (0, 0.0),\n",
       " (1, 0.20895760975438457)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = load_dataset_from_zst(settings.raw_data_dir / \"test_with_negatives.jsonl.zst\")\n",
    "\n",
    "# Decrease the test sample to run it locally\n",
    "test_texts = test_df[\"text\"].tolist()[:1000]\n",
    "test_hubs = test_df[\"hub\"].tolist()[:1000]\n",
    "test_labels = test_df[\"label\"].tolist()[:1000]\n",
    "\n",
    "\n",
    "probas = [model.predict_proba(text, hub) for text, hub in zip(test_texts, test_hubs)]\n",
    "\n",
    "list(zip(test_labels[:10], probas[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f437f74-7056-48e6-8f05-5f0547b46a87",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "Let's use some standard metric to estimate this model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46ffe1ec-b962-4584-83ba-64b0b67578b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.8016\n",
      "Log Loss: 1.5834\n",
      "Accuracy: 0.7430\n"
     ]
    }
   ],
   "source": [
    "probas = np.array(probas)\n",
    "labels = np.array(test_labels)\n",
    "\n",
    "# ROC AUC\n",
    "roc_auc = roc_auc_score(labels, probas)\n",
    "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# Log Loss\n",
    "ll = log_loss(labels, probas)\n",
    "print(f\"Log Loss: {ll:.4f}\")\n",
    "\n",
    "# Accuracy\n",
    "preds = (probas >= 0.5).astype(int)\n",
    "acc = accuracy_score(labels, preds)\n",
    "print(f\"Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d1eb28-d587-4137-aff3-f0cd49bb88c8",
   "metadata": {},
   "source": [
    "On this step it's hard to say if the results are good because it's our first model, but now we have something and are able to compare our future models to these metrics. However, our main goal is to use one specific metric to compare different models, which will be presented in a different notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
