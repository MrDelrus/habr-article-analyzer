{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d38c72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from habr_article_analyzer.data_loader import HabrDataset\n",
    "from habr_article_analyzer.datasets.lazy_ranking import FullLazyRankingDataset\n",
    "from habr_article_analyzer.metrics.ranking_metrics import RankingMetrics\n",
    "from habr_article_analyzer.models.baseline.baseline import BaselineWord2VecKNN\n",
    "from habr_article_analyzer.models.encoders.hub_averaging_encoder import HubEncoder\n",
    "from habr_article_analyzer.models.encoders.tf_idf_encoder import TextEncoder\n",
    "from habr_article_analyzer.models.predictors.ranking_nn import RankingModel\n",
    "from habr_article_analyzer.settings import data_settings, settings\n",
    "from habr_article_analyzer.targets import Target\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e56b728a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading dataset: 60408it [00:03, 16223.23it/s]\n"
     ]
    }
   ],
   "source": [
    "test_df = (\n",
    "    HabrDataset(\n",
    "        path=settings.raw_data_dir / \"test.jsonl.zst\",\n",
    "        batch_size=data_settings.batch_size,\n",
    "    )\n",
    "    .get_dataframe()\n",
    "    .sample(500)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b61efe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = Target(test_df, \"hubs\", sparse=True)\n",
    "hubs = targets.labels\n",
    "texts = test_df[\"text_markdown\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75c13f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "sergiy_text_encoder = TextEncoder(max_features=5000).load(\n",
    "    settings.models_dir / \"text_encoder.pt\"\n",
    ")\n",
    "sergiy_hub_encoder = HubEncoder(dim=5000).load(settings.models_dir / \"hub_encoder.pt\")\n",
    "sergiy_model = RankingModel(input_dim=10000)\n",
    "sergiy_model.load_state_dict(torch.load(settings.models_dir / \"bow_dssm_1.pt\"))\n",
    "sergiy_model.to(\"cuda\")\n",
    "sergiy_model_predictor = sergiy_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8060d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergiy/habr-article-analyzer/env/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['хотел'] not in stop_words.\n",
      "  warnings.warn(\n",
      "applying model to test dataset: 100%|██████████| 645/645 [00:21<00:00, 30.69it/s]\n"
     ]
    }
   ],
   "source": [
    "sergiy_hub_embeds = sergiy_hub_encoder.transform(hubs)\n",
    "sergiy_text_embeds = sergiy_text_encoder.transform(texts)\n",
    "sergiy_dataset = FullLazyRankingDataset(sergiy_text_embeds, sergiy_hub_embeds, targets)\n",
    "\n",
    "sergiy_predicts = []\n",
    "loader = DataLoader(sergiy_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features, labels in tqdm(loader, desc=\"applying model to test dataset\"):\n",
    "        gpu_features = features.to(\"cuda\")\n",
    "        gpu_predicts = sergiy_model_predictor(gpu_features)\n",
    "        for predict in gpu_predicts.to(\"cpu\"):\n",
    "            sergiy_predicts.append(predict.item())\n",
    "\n",
    "sergiy_predicts = np.array(sergiy_predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43f380cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nikita_model = BaselineWord2VecKNN.load(\n",
    "    settings.models_dir / \"baseline_word2vec_knn.pickle\"\n",
    ")\n",
    "nikita_hub_encoder = nikita_model.hub_encoder\n",
    "nikita_text_encoder = nikita_model.text_encoder\n",
    "nikita_model_predictor = nikita_model.predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3601b4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "applying model to test dataset: 100%|██████████| 645/645 [00:54<00:00, 11.89it/s]\n"
     ]
    }
   ],
   "source": [
    "nikita_hub_embeds = np.array([nikita_hub_encoder.encode(hub) for hub in hubs])\n",
    "nikita_text_embeds = np.array([nikita_text_encoder.encode(text) for text in texts])\n",
    "nikita_dataset = FullLazyRankingDataset(nikita_text_embeds, nikita_hub_embeds, targets)\n",
    "\n",
    "nikita_predicts = []\n",
    "loader = DataLoader(nikita_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "for features, labels in tqdm(loader, desc=\"applying model to test dataset\"):\n",
    "    predicts = nikita_model_predictor.model.predict_proba(features)\n",
    "    nikita_predicts.extend(predicts[:, 1])\n",
    "\n",
    "nikita_predicts = np.array(nikita_predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c21a1e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sergiy's dcg score: 0.10124032321219213\n",
      "Sergiy's ndcg score: 0.0751940535996023\n",
      "Nikita's dcg score: 0.043399153681384396\n",
      "Nikita's ndcg score: 0.028028323935908803\n"
     ]
    }
   ],
   "source": [
    "for name, predicts in [(\"Sergiy\", sergiy_predicts), (\"Nikita\", nikita_predicts)]:\n",
    "    predicts = np.reshape(np.array(predicts), shape=(len(test_df), len(targets)))\n",
    "    metrics = RankingMetrics(targets, predicts)\n",
    "    print(f\"{name}'s dcg score: {metrics.dcg().mean().item()}\")\n",
    "    print(f\"{name}'s ndcg score: {metrics.ndcg().mean().item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c614f915",
   "metadata": {},
   "source": [
    "Well, definetly not random ranking, but we have a lot of space for improvement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
