{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4bd9d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergiyar/.cache/pypoetry/virtualenvs/habr-article-analyzer-fSU603ju-py3.12/lib/python3.12/site-packages/sklearn/base.py:463: InconsistentVersionWarning: Trying to unpickle estimator TfidfTransformer from version 1.7.2 when using version 1.8.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/sergiyar/.cache/pypoetry/virtualenvs/habr-article-analyzer-fSU603ju-py3.12/lib/python3.12/site-packages/sklearn/base.py:463: InconsistentVersionWarning: Trying to unpickle estimator TfidfVectorizer from version 1.7.2 when using version 1.8.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from ml_training import settings\n",
    "from ml_training.models.baseline.bow_dssm import BoWDSSM\n",
    "from ml_training.models.encoders.hub_averaging_encoder import HubEncoder\n",
    "from ml_training.models.encoders.tf_idf_encoder import TextEncoder\n",
    "from ml_training.models.predictors.ranking_nn import RankingModel\n",
    "\n",
    "predictor = RankingModel(input_dim=10000)\n",
    "predictor.load_state_dict(torch.load(settings.Settings().models_dir / \"bow_dssm_1.pt\"))\n",
    "\n",
    "bow_dssm = BoWDSSM(\n",
    "    TextEncoder.load(settings.Settings().models_dir / \"text_encoder.pt\"),\n",
    "    HubEncoder.load(settings.Settings().models_dir / \"hub_encoder.pt\"),\n",
    "    predictor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e87cc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yandex: 0.9414007067680359\n",
      "natural_language_processing: 0.5178830623626709\n",
      "cpp: 0.28635796904563904\n",
      "1C: 0.5039178729057312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergiyar/.cache/pypoetry/virtualenvs/habr-article-analyzer-fSU603ju-py3.12/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:411: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['хотел'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for hub in [\"yandex\", \"natural_language_processing\", \"cpp\", \"1C\"]:\n",
    "    proba = bow_dssm.predict_proba(\"Яндекс ML, NLP, Поиск\", hub)\n",
    "    print(f\"{hub}: {proba}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a06f657-5629-4501-be85-23a9404d192d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_dssm.save(settings.Settings().models_dir / \"baseline_bow_nn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "137d2583-9e24-4966-bfc1-eb90b1359ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_training import settings\n",
    "from ml_training.models.baseline.bow_dssm import BoWDSSM\n",
    "\n",
    "loaded_bow_dssm = BoWDSSM.load(settings.Settings().models_dir / \"baseline_bow_nn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b62172cc-9816-4391-9567-d87835a55a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yandex: 0.9414007067680359\n",
      "natural_language_processing: 0.5178830623626709\n",
      "cpp: 0.28635796904563904\n",
      "1C: 0.5039178729057312\n"
     ]
    }
   ],
   "source": [
    "for hub in [\"yandex\", \"natural_language_processing\", \"cpp\", \"1C\"]:\n",
    "    proba = loaded_bow_dssm.predict_proba(\"Яндекс ML, NLP, Поиск\", hub)\n",
    "    print(f\"{hub}: {proba}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54d50c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hub encoder: 2392 hubs\n",
      "Text encoder: 5000 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergiyar/habr-article-analyzer/src/ml_training/ml_training/converters/export.py:74: UserWarning: # 'dynamic_axes' is not recommended when dynamo=True, and may lead to 'torch._dynamo.exc.UserError: Constraints violated.' Supply the 'dynamic_shapes' argument instead if export is unsuccessful.\n",
      "  torch.onnx.export(\n",
      "W1225 22:41:49.001000 647460 torch/onnx/_internal/exporter/_compat.py:114] Setting ONNX exporter to use operator set version 18 because the requested opset_version 15 is a lower version than we have implementations for. Automatic version conversion will be performed, which may not be successful at converting to the requested version. If version conversion is unsuccessful, the opset version of the exported model will be kept at 18. Please consider setting opset_version >=18 to leverage latest ONNX features\n",
      "W1225 22:41:49.517000 647460 torch/onnx/_internal/exporter/_registration.py:107] torchvision is not installed. Skipping torchvision::nms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `RankingModel([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `RankingModel([...]` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model version conversion is not supported by the onnxscript version converter and fallback is enabled. The model will be converted using the onnx C API (target version: 15).\n",
      "Failed to convert the model to the target version 15 using the ONNX C API. The model was not modified\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sergiyar/.cache/pypoetry/virtualenvs/habr-article-analyzer-fSU603ju-py3.12/lib/python3.12/site-packages/onnxscript/version_converter/__init__.py\", line 127, in call\n",
      "    converted_proto = _c_api_utils.call_onnx_api(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sergiyar/.cache/pypoetry/virtualenvs/habr-article-analyzer-fSU603ju-py3.12/lib/python3.12/site-packages/onnxscript/version_converter/_c_api_utils.py\", line 65, in call_onnx_api\n",
      "    result = func(proto)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/sergiyar/.cache/pypoetry/virtualenvs/habr-article-analyzer-fSU603ju-py3.12/lib/python3.12/site-packages/onnxscript/version_converter/__init__.py\", line 122, in _partial_convert_version\n",
      "    return onnx.version_converter.convert_version(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sergiyar/.cache/pypoetry/virtualenvs/habr-article-analyzer-fSU603ju-py3.12/lib/python3.12/site-packages/onnx/version_converter.py\", line 39, in convert_version\n",
      "    converted_model_str = C.convert_version(model_str, target_version)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: /github/workspace/onnx/version_converter/BaseConverter.h:68: adapter_lookup: Assertion `false` failed: No Adapter From Version $16 for Identity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n",
      "Applied 3 of general pattern rewrite rules.\n",
      "Predictor: input_dim=10000\n",
      "Metadata saved\n",
      "Model exported to /home/sergiyar/habr-article-analyzer/models/compressed.bowdssm\n",
      "File size: 61.27 MB\n"
     ]
    }
   ],
   "source": [
    "from ml_training.converters.export import export_model\n",
    "\n",
    "export_model(loaded_bow_dssm, settings.Settings().models_dir / \"compressed.bowdssm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5225865f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hub encoder: 2392 hubs, dim=5000\n",
      "Text encoder loaded\n",
      "Predictor loaded\n",
      "Metadata: version=1.0\n",
      "Model loaded from /home/sergiyar/habr-article-analyzer/models/compressed.bowdssm\n"
     ]
    }
   ],
   "source": [
    "from ml_training.converters.inference import BowDSSMInference\n",
    "\n",
    "model = BowDSSMInference(settings.Settings().models_dir / \"compressed.bowdssm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6f90a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yandex: 0.9414006471633911\n",
      "natural_language_processing: 0.5178832411766052\n",
      "cpp: 0.28635770082473755\n",
      "1C: 0.5039184093475342\n"
     ]
    }
   ],
   "source": [
    "for hub in [\"yandex\", \"natural_language_processing\", \"cpp\", \"1C\"]:\n",
    "    proba = model.predict_proba(\"Яндекс ML, NLP, Поиск\", hub)\n",
    "    print(f\"{hub}: {proba}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "075fb672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hub encoder: 1 hubs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergiyar/habr-article-analyzer/src/ml_training/ml_training/converters/export.py:74: UserWarning: # 'dynamic_axes' is not recommended when dynamo=True, and may lead to 'torch._dynamo.exc.UserError: Constraints violated.' Supply the 'dynamic_shapes' argument instead if export is unsuccessful.\n",
      "  torch.onnx.export(\n",
      "W1225 22:51:25.410000 647460 torch/onnx/_internal/exporter/_compat.py:114] Setting ONNX exporter to use operator set version 18 because the requested opset_version 15 is a lower version than we have implementations for. Automatic version conversion will be performed, which may not be successful at converting to the requested version. If version conversion is unsuccessful, the opset version of the exported model will be kept at 18. Please consider setting opset_version >=18 to leverage latest ONNX features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text encoder: 5000 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1225 22:51:25.785000 647460 torch/onnx/_internal/exporter/_registration.py:107] torchvision is not installed. Skipping torchvision::nms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `RankingModel([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `RankingModel([...]` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model version conversion is not supported by the onnxscript version converter and fallback is enabled. The model will be converted using the onnx C API (target version: 15).\n",
      "Failed to convert the model to the target version 15 using the ONNX C API. The model was not modified\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sergiyar/.cache/pypoetry/virtualenvs/habr-article-analyzer-fSU603ju-py3.12/lib/python3.12/site-packages/onnxscript/version_converter/__init__.py\", line 127, in call\n",
      "    converted_proto = _c_api_utils.call_onnx_api(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sergiyar/.cache/pypoetry/virtualenvs/habr-article-analyzer-fSU603ju-py3.12/lib/python3.12/site-packages/onnxscript/version_converter/_c_api_utils.py\", line 65, in call_onnx_api\n",
      "    result = func(proto)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/sergiyar/.cache/pypoetry/virtualenvs/habr-article-analyzer-fSU603ju-py3.12/lib/python3.12/site-packages/onnxscript/version_converter/__init__.py\", line 122, in _partial_convert_version\n",
      "    return onnx.version_converter.convert_version(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sergiyar/.cache/pypoetry/virtualenvs/habr-article-analyzer-fSU603ju-py3.12/lib/python3.12/site-packages/onnx/version_converter.py\", line 39, in convert_version\n",
      "    converted_model_str = C.convert_version(model_str, target_version)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: /github/workspace/onnx/version_converter/BaseConverter.h:68: adapter_lookup: Assertion `false` failed: No Adapter From Version $16 for Identity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n",
      "Applied 3 of general pattern rewrite rules.\n",
      "Predictor: input_dim=10000\n",
      "Metadata saved\n",
      "Model exported to /home/sergiyar/habr-article-analyzer/models/compressed_nano.bowdssm\n",
      "File size: 0.16 MB\n",
      "Hub encoder: 1 hubs, dim=5000\n",
      "Text encoder loaded\n",
      "Predictor loaded\n",
      "Metadata: version=1.0\n",
      "Model loaded from /home/sergiyar/habr-article-analyzer/models/compressed_nano.bowdssm\n",
      "yandex: 0.5437959432601929\n",
      "natural_language_processing: 0.5437959432601929\n",
      "cpp: 0.5437959432601929\n",
      "1C: 0.5437959432601929\n"
     ]
    }
   ],
   "source": [
    "from ml_training.models.predictors.ranking_nn import RankingModel\n",
    "\n",
    "nano_predictor = RankingModel(input_dim=10000, hidden_dims=[2, 2, 2])\n",
    "loaded_bow_dssm.hub_encoder.hub_to_vec = {\n",
    "    \"1C\": loaded_bow_dssm.hub_encoder.hub_to_vec[\"1C\"]\n",
    "}\n",
    "loaded_bow_dssm.predictor = nano_predictor\n",
    "loaded_bow_dssm.predictor.eval()\n",
    "\n",
    "export_model(\n",
    "    loaded_bow_dssm, settings.Settings().models_dir / \"compressed_nano.bowdssm\"\n",
    ")\n",
    "model_nano = BowDSSMInference(\n",
    "    settings.Settings().models_dir / \"compressed_nano.bowdssm\"\n",
    ")\n",
    "\n",
    "for hub in [\"yandex\", \"natural_language_processing\", \"cpp\", \"1C\"]:\n",
    "    proba = model_nano.predict_proba(\"Яндекс ML, NLP, Поиск\", hub)\n",
    "    print(f\"{hub}: {proba}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "habr-article-analyzer-fSU603ju-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
